import streamlit as st
import requests
from bs4 import BeautifulSoup
from pptx import Presentation
from pptx.util import Inches, Pt
import io
import json
import re
import random
import zipfile
import time

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="äº¬ä¸œç›´æ’­æ‰‹å¡ç”Ÿæˆå™¨ Webç‰ˆ",
    page_icon="âš¡",
    layout="wide"
)

# --- å·¥å…·å‡½æ•° ---

# ä¼ªè£…æµè§ˆå™¨å¤´
def get_headers():
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ]
    return {
        "User-Agent": random.choice(user_agents),
        "Referer": "https://item.jd.com/",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9"
    }

def scrape_jd_sku(sku):
    """æŠ“å–äº¬ä¸œå•†å“æ ‡é¢˜å’Œä¸»å›¾"""
    url = f"https://item.jd.com/{sku}.html"
    info = {"sku": sku, "title": "", "image_url": ""}
    
    try:
        r = requests.get(url, headers=get_headers(), timeout=10)
        r.encoding = r.apparent_encoding
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # 1. æŠ“æ ‡é¢˜
        raw_title = ""
        title_tag = soup.select_one("div.sku-name")
        if title_tag: raw_title = title_tag.get_text(strip=True)
        if not raw_title and soup.title: raw_title = soup.title.string.split('-')[0].strip()
        
        if raw_title:
            info["title"] = raw_title.replace("äº¬ä¸œ", "").replace("è‡ªè¥", "").strip()
        else:
            info["title"] = f"å•†å“_{sku}"

        # 2. æŠ“ä¸»å›¾
        candidates = []
        img_tag = soup.select_one("#spec-img")
        if img_tag:
            candidates.append(img_tag.get('data-origin'))
            candidates.append(img_tag.get('src'))
        
        # æ­£åˆ™è¡¥å……åŒ¹é…
        patterns = re.findall(r'//img\d{1,2}\.360buyimg\.com/n[01]/jfs/[^"]+\.jpg', r.text)
        candidates.extend(patterns)

        for img in candidates:
            if img and "jfs" in img and ".jpg" in img:
                if not img.startswith("http"):
                    img = "https:" + img if img.startswith("//") else "https://" + img
                # æ›¿æ¢ä¸ºé«˜æ¸…å¤§å›¾
                img = img.replace("/n1/", "/n0/").replace("/n5/", "/n0/")
                info["image_url"] = img
                break
                
        return info
    except Exception as e:
        st.error(f"SKU {sku} æŠ“å–å¤±è´¥: {e}")
        return None

def download_image_to_memory(url):
    """ä¸‹è½½å›¾ç‰‡åˆ°å†…å­˜å­—èŠ‚æµ"""
    if not url: return None
    try:
        r = requests.get(url, headers=get_headers(), timeout=10, verify=False)
        return io.BytesIO(r.content)
    except Exception as e:
        st.error(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {e}")
        return None

def call_ai_generate_points(product_name, api_key, base_url):
    """è°ƒç”¨ AI ç”Ÿæˆå–ç‚¹"""
    if not api_key:
        return {"selling_point_1": "è¯·å¡«å†™API Key", "selling_point_2": "ä»¥ç”Ÿæˆæ™ºèƒ½å–ç‚¹"}

    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    prompt = f"""
    ä½ æ˜¯ä¸€åå¸¦è´§è¿‡äº¿çš„é‡‘ç‰Œä¸»æ’­ã€‚è¯·æ ¹æ®å•†å“åã€{product_name}ã€‘ï¼Œæç‚¼ 4 ä¸ªé€‚åˆå£æ’­çš„â€œé«˜è½¬åŒ–å–ç‚¹â€ã€‚
    è¦æ±‚ï¼š
    1. **å£è¯­åŒ–**ï¼šåƒè·Ÿç²‰ä¸èŠå¤©ã€‚
    2. **æ ¼å¼**ï¼šéœ€ç”Ÿæˆ 4 æ¡ã€‚
       - æ ¸å¿ƒçŸ­å¥ï¼ˆ5-8å­—ï¼‰ï¼šé†’ç›®ã€‚
       - è¯¦ç»†è§£é‡Šï¼ˆ20-40å­—ï¼‰ï¼šç®€çŸ­æœ‰åŠ›ã€‚
    è¾“å‡ºæ ¼å¼ï¼šè¿”å› JSONï¼Œkey ä¸º selling_point_1 åˆ° selling_point_4ã€‚
    """
    data = {
        "model": "deepseek-chat", # è¿™é‡Œå‡è®¾ç”¨æˆ·å¤šæ•°ç”¨ deepseekï¼Œä¹Ÿå¯ä»¥åšæˆé€šè¿‡ input è·å–
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.8,
        "response_format": {"type": "json_object"}
    }

    try:
        resp = requests.post(f"{base_url}/chat/completions", headers=headers, json=data, timeout=30)
        result = resp.json()
        if 'error' in result:
            st.error(f"AI æ¥å£æŠ¥é”™: {result['error']['message']}")
            return {}
        content = result['choices'][0]['message']['content']
        return json.loads(content)
    except Exception as e:
        st.error(f"AI è¯·æ±‚å¼‚å¸¸: {e}")
        return {}

def process_ppt(template_file, data_list):
    """æ‰¹é‡ç”Ÿæˆ PPT å¹¶æ‰“åŒ…æˆ ZIP"""
    zip_buffer = io.BytesIO()
    
    with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zip_file:
        for data in data_list:
            # æ¯æ¬¡éƒ½éœ€è¦é‡æ–°åŠ è½½æ¨¡æ¿ï¼ˆå› ä¸ºè¦ä¿®æ”¹å®ƒï¼‰
            template_file.seek(0)
            prs = Presentation(template_file)
            slide = prs.slides[0]

            # æ–‡æœ¬æ›¿æ¢å‡½æ•°
            def replace_text(name, text):
                for shape in slide.shapes:
                    if shape.name == name and shape.has_text_frame:
                        shape.text_frame.text = str(text)
                        return
                    if shape.shape_type == 6: # Group
                        for sub in shape.shapes:
                            if sub.name == name and sub.has_text_frame:
                                sub.text_frame.text = str(text)
                                return

            # æ‰§è¡Œæ›¿æ¢
            replace_text("product_name", data['title'])
            replace_text("product_sku", data['sku'])
            replace_text("price_live", data['price'])
            
            points = data.get('points', {})
            replace_text("selling_point_1", points.get('selling_point_1', ''))
            replace_text("selling_point_2", points.get('selling_point_2', ''))
            replace_text("selling_point_3", points.get('selling_point_3', ''))
            replace_text("selling_point_4", points.get('selling_point_4', ''))

            # å›¾ç‰‡æ›¿æ¢
            if data['image_bytes']:
                found_img = False
                for shape in slide.shapes:
                    if shape.name == "product_image":
                        left, top, width, height = shape.left, shape.top, shape.width, shape.height
                        # ç§»é™¤æ—§å›¾
                        sp = shape._element
                        sp.getparent().remove(sp)
                        # æ·»åŠ æ–°å›¾
                        slide.shapes.add_picture(data['image_bytes'], left, top, width, height)
                        found_img = True
                        break
            
            # ä¿å­˜å•ä¸ª PPT åˆ°å†…å­˜
            ppt_buffer = io.BytesIO()
            prs.save(ppt_buffer)
            # æ·»åŠ åˆ° ZIP
            zip_file.writestr(f"{data['sku']}.pptx", ppt_buffer.getvalue())
    
    return zip_buffer

# --- UI å¸ƒå±€ ---

st.title("âš¡ äº¬ä¸œç›´æ’­æ‰‹å¡å…¨è‡ªåŠ¨ç”Ÿæˆå™¨ (Webç‰ˆ)")
st.markdown("ä¸Šä¼  PPT æ¨¡æ¿ï¼Œè¾“å…¥ SKUï¼Œè‡ªåŠ¨æŠ“å–ä¿¡æ¯ + AI ç”Ÿæˆå–ç‚¹ï¼Œä¸€é”®å¯¼å‡º PPTã€‚")

with st.sidebar:
    st.header("ğŸ§  1. AI é…ç½®")
    api_key = st.text_input("API Key", type="password", help="æ¨èä½¿ç”¨ DeepSeek API")
    base_url = st.text_input("Base URL", value="https://api.deepseek.com")
    st.info("å¦‚æœæ²¡æœ‰ Keyï¼Œå–ç‚¹éƒ¨åˆ†å°†ä¸ºç©ºï¼Œä½†åŸºç¡€ä¿¡æ¯ä»ä¼šç”Ÿæˆã€‚")
    
    st.divider()
    st.header("ğŸ“‚ 2. æ¨¡æ¿è®¾ç½®")
    uploaded_template = st.file_uploader("ä¸Šä¼  .pptx æ¨¡æ¿æ–‡ä»¶", type=["pptx"])
    if not uploaded_template:
        st.warning("è¯·å…ˆä¸Šä¼ æ¨¡æ¿æ–‡ä»¶ï¼æ¨¡æ¿ä¸­éœ€åŒ…å« product_name, product_sku, price_live, product_image ç­‰å‘½åå…ƒç´ ã€‚")

st.header("ğŸ“ 3. å•†å“ä¸ä»·æ ¼")
col1, col2 = st.columns([3, 1])
with col1:
    sku_input = st.text_area("è¾“å…¥ SKU (æ”¯æŒé€—å·ã€ç©ºæ ¼æˆ–æ¢è¡Œåˆ†éš”)", height=150, placeholder="ä¾‹å¦‚ï¼š1000123456, 1000888888")
with col2:
    price_input = st.text_input("ç›´æ’­ä¸“äº«ä»·", value="9.9")
    st.caption("æ‰€æœ‰å•†å“å°†ä½¿ç”¨æ­¤ç»Ÿä¸€ä»·æ ¼")

# --- æ‰§è¡Œé€»è¾‘ ---

if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", type="primary", use_container_width=True):
    if not uploaded_template:
        st.error("âŒ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PPT æ¨¡æ¿æ–‡ä»¶ï¼")
    elif not sku_input.strip():
        st.error("âŒ è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ª SKUï¼")
    else:
        # 1. å¤„ç† SKU åˆ—è¡¨
        raw_skus = sku_input.replace('ï¼Œ', ',').replace('\n', ',').replace(' ', ',')
        skus = [s.strip() for s in raw_skus.split(',') if s.strip()]
        
        processed_data = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # 2. å¾ªç¯å¤„ç†
        for idx, sku in enumerate(skus):
            status_text.text(f"æ­£åœ¨å¤„ç† ({idx+1}/{len(skus)}): SKU {sku} ...")
            
            # æŠ“å–
            info = scrape_jd_sku(sku)
            if not info:
                continue
                
            info['price'] = price_input
            
            # AI ç”Ÿæˆ
            if api_key:
                info['points'] = call_ai_generate_points(info['title'], api_key, base_url)
            else:
                info['points'] = {}
            
            # ä¸‹è½½å›¾ç‰‡
            info['image_bytes'] = download_image_to_memory(info['image_url'])
            
            processed_data.append(info)
            progress_bar.progress((idx + 1) / len(skus))
            
        status_text.text("æ­£åœ¨ç”Ÿæˆ PPT æ–‡ä»¶...")
        
        # 3. ç”Ÿæˆ PPT å‹ç¼©åŒ…
        if processed_data:
            zip_io = process_ppt(uploaded_template, processed_data)
            
            st.success(f"ğŸ‰ æˆåŠŸç”Ÿæˆ {len(processed_data)} ä¸ªæ‰‹å¡ï¼")
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ‰€æœ‰æ‰‹å¡ (ZIPå‹ç¼©åŒ…)",
                data=zip_io.getvalue(),
                file_name="Live_Cards_Output.zip",
                mime="application/zip",
                type="primary"
            )
        else:
            st.error("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥ SKU æ˜¯å¦æ­£ç¡®ã€‚")
