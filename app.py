import streamlit as st
import pandas as pd
from pptx import Presentation
import os
import time
import requests
from bs4 import BeautifulSoup
import json
import re
import random
import shutil
import copy
import ast
from io import BytesIO

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="äº¬ä¸œç›´æ’­æ‰‹å¡ç”Ÿæˆå™¨ Webç‰ˆ", page_icon="âš¡", layout="wide")

# --- æ ¸å¿ƒé€»è¾‘ ---
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
]

def get_headers():
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Referer": "[https://item.jd.com/](https://item.jd.com/)",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Connection": "keep-alive"
    }

def scrape_jd_sku(sku):
    url = f"[https://item.jd.com/](https://item.jd.com/){sku}.html"
    info = {"sku": sku, "title": "", "image_url": ""}
    
    try:
        r = requests.get(url, headers=get_headers(), timeout=15)
        if "verify" in r.url or "passport" in r.url:
            return None

        r.encoding = r.apparent_encoding
        soup = BeautifulSoup(r.text, 'html.parser')
        
        raw_title = ""
        title_tag = soup.select_one("div.sku-name")
        if title_tag: raw_title = title_tag.get_text(strip=True)
        if not raw_title and soup.title: raw_title = soup.title.string.split('-')[0].strip()
        
        if raw_title:
            info["title"] = raw_title.replace("äº¬ä¸œ", "").replace("è‡ªè¥", "").strip()
        else:
            return None

        candidates = []
        img_tag = soup.select_one("#spec-img")
        if img_tag:
            candidates.append(img_tag.get('data-origin'))
            candidates.append(img_tag.get('src'))
        patterns = re.findall(r'//img\d{1,2}\.360buyimg\.com/n[01]/jfs/[^"]+\.jpg', r.text)
        candidates.extend(patterns)

        valid_imgs = []
        for img in candidates:
            if img and "jfs" in img and ".jpg" in img:
                if not img.startswith("http"):
                    img = "https:" + img if img.startswith("//") else "https://" + img
                img = img.replace("/n1/", "/n0/").replace("/n5/", "/n0/")
                valid_imgs.append(img)

        if valid_imgs:
            info["image_url"] = valid_imgs[0]
        
        return info
    except Exception as e:
        return None

def download_image(url, sku):
    if not url: return None
    try:
        r = requests.get(url, headers=get_headers(), timeout=15)
        return BytesIO(r.content)
    except:
        return None

def extract_points_with_regex(text):
    """
    å½“JSONè§£æå¤±è´¥æ—¶ï¼Œä½¿ç”¨æ­£åˆ™æš´åŠ›æå–å–ç‚¹
    """
    points = {}
    for i in range(1, 5):
        key = f"selling_point_{i}"
        # åŒ¹é…æ¨¡å¼ï¼škey åé¢è·Ÿç€å†’å·ï¼Œç„¶åæ˜¯å¼•å·ï¼Œç„¶åæ˜¯å†…å®¹
        pattern = re.search(rf"['\"]?{key}['\"]?\s*:\s*['\"](.*?)['\"]", text, re.DOTALL)
        if pattern:
            points[key] = pattern.group(1)
    return points

def call_ai(product_name, api_key, base_url):
    if not api_key: return {}
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„ç”µå•†é‡‘ç‰Œé€‰å“æ€»ç›‘ï¼Œæ“…é•¿æŒ–æ˜â€œç—›ç‚¹è¥é”€â€å’Œâ€œé«˜è½¬åŒ–è¯æœ¯â€ã€‚
    è¯·æ ¹æ®å•†å“åç§°ã€{product_name}ã€‘ï¼Œæ·±åº¦å‰–æç”¨æˆ·ç—›ç‚¹ï¼Œæ’°å†™ 4 ä¸ªæå…·ç…½åŠ¨æ€§å’Œè½¬åŒ–åŠ›çš„ç›´æ’­æ‰‹å¡å–ç‚¹ã€‚

    ã€æ ¸å¿ƒè¦æ±‚ã€‘ï¼š
    1. **æ‹’ç»ç©ºè¯**ï¼šä¸è¦åªè¯´â€œå¥½ç”¨â€ï¼Œè¦è¯´å‡ºè§£å†³ä»€ä¹ˆå…·ä½“éº»çƒ¦ã€‚
    2. **ç»“æ„ä¸¥æ ¼**ï¼šé‡‡ç”¨â€œç—›ç‚¹åœºæ™¯ + è§£å†³æ–¹æ¡ˆ + å¸¦æ¥çš„åˆ©ç›Šâ€çš„ç»“æ„ã€‚
    3. **è¯¦ç»†å…·ä½“**ï¼šæ¯æ¡å–ç‚¹éœ€åŒ…å«ä¸€ä¸ªã€å¸ç›çŸ­æ ‡é¢˜ã€‘ï¼ˆ6-10å­—ï¼‰å’Œä¸€æ®µã€è¯¦ç»†ç—›ç‚¹é˜è¿°ã€‘ï¼ˆ30-50å­—ï¼‰ã€‚
    4. **æ•°é‡**ï¼šå¿…é¡»ç”Ÿæˆ 4 æ¡ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š
    è¯·ç›´æ¥è¿”å›çº¯ JSON æ ¼å¼æ•°æ®ï¼Œé”®åå›ºå®šä¸ºï¼šselling_point_1, selling_point_2, selling_point_3, selling_point_4ã€‚
    """
    
    data = {
        "model": "deepseek-chat", 
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "response_format": {"type": "json_object"}
    }
    try:
        resp = requests.post(f"{base_url}/chat/completions", headers=headers, json=data, timeout=40)
        content = resp.json()['choices'][0]['message']['content']
        
        # æ¸…æ´— Markdown
        content = content.replace("```json", "").replace("```", "").strip()
        
        # å¤šé‡è§£æä¿éšœ
        try:
            return json.loads(content)
        except:
            try:
                return ast.literal_eval(content)
            except:
                return extract_points_with_regex(content)
    except:
        return {}

def duplicate_slide(pres):
    source = pres.slides[0]
    blank_slide_layout = pres.slide_layouts[6] 
    dest = pres.slides.add_slide(blank_slide_layout)

    for shp in source.shapes:
        el = shp.element
        newel = copy.deepcopy(el)
        dest.shapes._spTree.insert_element_before(newel, 'p:extLst')
    return dest

def fill_slide(slide, data):
    def replace(name, text):
        text_str = str(text)
        # é˜²å¥—å¨ƒæ¸…æ´—
        if text_str.strip().startswith("{") and "selling_point" in text_str:
             text_str = "AIç”Ÿæˆæ ¼å¼é”™è¯¯ï¼Œè¯·æ‰‹åŠ¨ä¿®æ”¹"

        for shape in slide.shapes:
            if shape.name == name and shape.has_text_frame:
                shape.text_frame.text = text_str
                return
            if shape.shape_type == 6: 
                for sub in shape.shapes:
                    if sub.name == name and sub.has_text_frame:
                        sub.text_frame.text = text_str
                        return

    replace("product_name", data['title'])
    replace("product_sku", data['sku']) 
    replace("price_live", data['price'])
    
    points = data.get('points', {})
    if not points:
        for i in range(1, 5):
            replace(f"selling_point_{i}", "æ™ºèƒ½å–ç‚¹ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ")
    else:
        for i in range(1, 5):
            content = points.get(f'selling_point_{i}', '')
            content = re.sub(r'^\d+\.?\s*', '', str(content))
            replace(f"selling_point_{i}", content)

    if data['image_data']:
        for shape in slide.shapes:
            if shape.name == "product_image":
                left, top, width, height = shape.left, shape.top, shape.width, shape.height
                sp = shape._element
                sp.getparent().remove(sp)
                slide.shapes.add_picture(data['image_data'], left, top, width, height)
                break

# --- ç½‘é¡µç•Œé¢ ---
st.title("âš¡ äº¬ä¸œç›´æ’­æ‰‹å¡å…¨è‡ªåŠ¨ç”Ÿæˆå™¨ (V4.2 ç»ˆæç¨³å®šç‰ˆ)")
st.markdown("å‡çº§è¯´æ˜ï¼šå¢å¼ºäº†å¯¹ AI å›å¤æ ¼å¼çš„å…¼å®¹æ€§ï¼Œæœç»ä¹±ç ï¼")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    api_key = st.text_input("AI API Key", type="password", help="è¾“å…¥DeepSeek Key")
    base_url = st.text_input("Base URL", value="[https://api.deepseek.com](https://api.deepseek.com)")
    
    st.markdown("---")
    st.info("ğŸ’¡ è¯·ç¡®ä¿ã€ç›´æ’­æ‰‹å¡æ¨¡æ¿.pptxã€‘å·²ä¸Šä¼ åˆ°æœåŠ¡å™¨ç›®å½•")
    
    uploaded_template = st.file_uploader("æˆ–ä¸Šä¼ ä½ çš„PPTæ¨¡æ¿", type="pptx")
    if uploaded_template:
        with open("ç›´æ’­æ‰‹å¡æ¨¡æ¿.pptx", "wb") as f:
            f.write(uploaded_template.getbuffer())
        st.success("æ¨¡æ¿å·²æ›´æ–°ï¼")

# ä¸»ç•Œé¢
col1, col2 = st.columns([1, 1])
with col1:
    skus_input = st.text_area("1. è¾“å…¥ SKU (æ‰¹é‡ï¼Œé€—å·æˆ–æ¢è¡Œåˆ†éš”)", height=200, placeholder="1000123456\n1000888888")
with col2:
    prices_input = st.text_area("2. è¾“å…¥ç›´æ’­ä¸“äº«ä»· (å¯¹åº”å·¦ä¾§SKUé¡ºåº)", height=200, placeholder="9.9\n12.8\n(å¦‚æœåªå¡«ä¸€ä¸ªï¼Œåˆ™å…¨éƒ¨é€šç”¨)")
    st.caption("æ³¨ï¼šç¬¬ä¸€è¡Œä»·æ ¼å¯¹åº”ç¬¬ä¸€è¡ŒSKUï¼Œä»¥æ­¤ç±»æ¨ã€‚å¦‚æœä»·æ ¼è¾“å°‘äº†ï¼Œå‰©ä¸‹çš„å•†å“ä¼šè‡ªåŠ¨å¤ç”¨æœ€åä¸€ä¸ªä»·æ ¼ã€‚")

if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆåˆé›†", type="primary"):
    if not skus_input:
        st.error("è¯·è¾“å…¥ SKU")
        st.stop()
        
    if not os.path.exists("ç›´æ’­æ‰‹å¡æ¨¡æ¿.pptx"):
        st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ï¼è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ¨¡æ¿ã€‚")
        st.stop()
    
    prs = Presentation("ç›´æ’­æ‰‹å¡æ¨¡æ¿.pptx")
    
    skus_text = skus_input.replace('ï¼Œ', ',').replace('\n', ',').replace(' ', ',')
    skus = [s.strip() for s in skus_text.split(',') if s.strip()]
    
    prices_text = prices_input.replace('ï¼Œ', ',').replace('\n', ',').replace(' ', ',')
    prices = [p.strip() for p in prices_text.split(',') if p.strip()]
    if not prices: prices = ["9.9"]
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    success_count = 0
    
    for i, sku in enumerate(skus):
        if i > 0:
            sleep_time = random.uniform(3, 6)
            status_text.text(f"â³ é˜²å°æš‚åœ {int(sleep_time)} ç§’...")
            time.sleep(sleep_time)
            
        status_text.text(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(skus)} ä¸ªå•†å“: {sku} ...")
        
        current_price = prices[i] if i < len(prices) else prices[-1]
        
        info = scrape_jd_sku(sku)
        if not info:
            st.warning(f"SKU {sku} æŠ“å–å¤±è´¥ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        info['price'] = current_price
        info['image_data'] = download_image(info['image_url'], sku)
        
        if api_key:
            info['points'] = call_ai(info['title'], api_key, base_url)
        else:
            info['points'] = {}
            
        if i == 0:
            current_slide = prs.slides[0]
        else:
            current_slide = duplicate_slide(prs)
            
        fill_slide(current_slide, info)
        success_count += 1
        
        progress_bar.progress((i + 1) / len(skus))
    
    status_text.text("æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
    
    output_ppt = BytesIO()
    prs.save(output_ppt)
    output_ppt.seek(0)
    
    if success_count > 0:
        st.success(f"ğŸ‰ æˆåŠŸç”Ÿæˆ {success_count} å¼ æ‰‹å¡ï¼")
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ç›´æ’­æ‰‹å¡åˆé›† (PPTX)",
            data=output_ppt,
            file_name=f"ç›´æ’­æ‰‹å¡åˆé›†_{time.strftime('%m%d_%H%M')}.pptx",
            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
        )
    else:
        st.error("æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆæ‰‹å¡ï¼Œè¯·æ£€æŸ¥ SKU æˆ–ç½‘ç»œã€‚")
